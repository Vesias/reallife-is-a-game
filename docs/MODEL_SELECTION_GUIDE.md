# KI-Modell Auswahl-Leitfaden f√ºr LifeQuest
*AI Model Selection Guide for LifeQuest*

## √úbersicht / Overview

Dieser Leitfaden hilft Entwicklern und Produktmanagern dabei, das optimale KI-Modell f√ºr verschiedene LifeQuest-Features auszuw√§hlen, basierend auf Anwendungsfall, Performance-Anforderungen und Kosteneffizienz.

*This guide helps developers and product managers select the optimal AI model for different LifeQuest features based on use case, performance requirements, and cost efficiency.*

## üéØ Modell-√úbersicht / Model Overview

### Verf√ºgbare KI-Modelle / Available AI Models

| Modell | Hauptst√§rken | Kosten | Latenz | Kontext |
|--------|-------------|--------|--------|---------|
| **Grok 4** | Complex reasoning, Probleml√∂sung | ‚Ç¨0.002/1M tokens | 2-4s | 256K |
| **GPT-5** | Coding, Agentic tasks, Vielseitigkeit | ‚Ç¨0.003/1M tokens | 1-3s | 128K |
| **GPT-5 Mini** | Schnelle Antworten, Kosteneffizienz | ‚Ç¨0.0002/1M tokens | 0.5-1s | 32K |
| **O3 Deep Research** | Tiefgehende Analyse, Forschung | ‚Ç¨0.02/1M tokens | 5-10s | 512K |
| **GPT Image 1** | Bildgenerierung | ‚Ç¨0.04/Bild | 3-8s | N/A |

## üöÄ Anwendungsfall-Matrix / Use Case Matrix

### 1. Quest-Generierung / Quest Generation

#### ‚úÖ Empfohlenes Modell: **Grok 4**
```typescript
// Beste Wahl f√ºr personalisierte Quest-Erstellung
const questGenerator = new AIQuestGenerator({
  model: 'grok-4',
  temperature: 0.7,
  maxTokens: 2048
});

// Anwendungsfall
await questGenerator.generatePersonalizedQuest({
  userProfile: complexUserProfile,
  questType: 'learning_challenge',
  difficulty: 'adaptive'
});
```

**Warum Grok 4?**
- ‚úÖ Hervorragendes Reasoning f√ºr komplexe Personalisierung
- ‚úÖ Versteht Nuancen in Nutzerverhalten
- ‚úÖ Gute Balance zwischen Qualit√§t und Kosten
- ‚úÖ 256K Kontext f√ºr umfassende Nutzerprofile

**Alternativen:**
- GPT-5: Wenn zus√§tzliche Coding-Quests generiert werden
- GPT-5 Mini: F√ºr einfache, schnelle Quest-Vorschl√§ge

### 2. Code-Generierung und Programmier-Hilfe / Code Generation

#### ‚úÖ Empfohlenes Modell: **GPT-5**
```typescript
// Optimiert f√ºr Code-Generierung
const codeAssistant = new CodeQuestAssistant({
  model: 'gpt-5',
  temperature: 0.3,
  specialization: 'coding'
});

// Anwendungsfall
await codeAssistant.generateCodingChallenge({
  language: 'typescript',
  difficulty: 'intermediate',
  topic: 'data_structures'
});
```

**Warum GPT-5?**
- ‚úÖ State-of-the-art Code-Generierung
- ‚úÖ Versteht moderne Frameworks und Libraries
- ‚úÖ Exzellent f√ºr Debugging und Code-Review
- ‚úÖ Optimiert f√ºr agentic tasks

**Alternativen:**
- Grok 4: F√ºr konzeptionelle Code-Erkl√§rungen
- GPT-5 Mini: F√ºr einfache Syntax-Hilfen

### 3. Schnelle Interaktionen / Quick Interactions

#### ‚úÖ Empfohlenes Modell: **GPT-5 Mini**
```typescript
// F√ºr schnelle, kosteneffiziente Antworten
const quickResponse = new QuickAIService({
  model: 'gpt-5-mini',
  temperature: 0.5,
  maxTokens: 512
});

// Anwendungsfall
await quickResponse.generateMotivationalMessage(userMood);
await quickResponse.provideQuickHint(questProgress);
await quickResponse.answerFAQ(userQuestion);
```

**Warum GPT-5 Mini?**
- ‚úÖ 10x kosteng√ºnstiger als gr√∂√üere Modelle
- ‚úÖ Sub-Sekunde Latenz
- ‚úÖ Perfekt f√ºr h√§ufige, einfache Anfragen
- ‚úÖ Geringer Ressourcenverbrauch

**Anwendungsf√§lle:**
- Motivations-Nachrichten
- Schnelle Tipps und Hints
- FAQ-Beantwortung
- Einfache Validierungen

### 4. Tiefgehende Analyse / Deep Analysis

#### ‚úÖ Empfohlenes Modell: **O3 Deep Research**
```typescript
// F√ºr komplexe Analyse und Forschung
const deepAnalyzer = new DeepAnalysisAI({
  model: 'o3-deep-research',
  temperature: 0.2,
  maxTokens: 8192
});

// Anwendungsfall
await deepAnalyzer.analyzeUserLearningPatterns({
  historicalData: userLearningHistory,
  timeframe: '90d',
  analysisDepth: 'comprehensive'
});
```

**Warum O3 Deep Research?**
- ‚úÖ Un√ºbertroffen f√ºr komplexe Analysen
- ‚úÖ 512K Kontext f√ºr umfassende Datenverarbeitung
- ‚úÖ Hervorragend f√ºr Pattern-Erkennung
- ‚úÖ Detaillierte Insights und Empfehlungen

**Anwendungsf√§lle:**
- Nutzer-Verhalten Analyse
- Lernmuster-Erkennung
- Performance-Optimierung
- Markttrend-Analyse

### 5. Visuelle Inhalte / Visual Content

#### ‚úÖ Empfohlenes Modell: **GPT Image 1**
```typescript
// F√ºr Bildgenerierung und visuelle Inhalte
const imageGenerator = new AIImageService({
  model: 'gpt-image-1',
  quality: 'hd',
  size: '1024x1024'
});

// Anwendungsfall
await imageGenerator.generateQuestImage({
  questType: 'learning_adventure',
  style: 'modern_illustration',
  theme: userPreferences.visualStyle
});
```

**Warum GPT Image 1?**
- ‚úÖ State-of-the-art Bildqualit√§t
- ‚úÖ Konsistente Ergebnisse
- ‚úÖ Gute Integration mit Text-Prompts
- ‚úÖ Verschiedene Stile und Formate

**Anwendungsf√§lle:**
- Quest-Thumbnails
- Achievement Badges
- Personalisierte Avatare
- Illustrationen f√ºr Lerninhalte

## üìä Kosten-Nutzen-Analyse / Cost-Benefit Analysis

### Kostenvergleich f√ºr typische LifeQuest-Operationen

```typescript
// lib/ai/cost-calculator.ts
export class AICostCalculator {
  private modelCosts = {
    'grok-4': 0.002,      // $0.002 per 1M tokens
    'gpt-5': 0.003,       // $0.003 per 1M tokens
    'gpt-5-mini': 0.0002, // $0.0002 per 1M tokens
    'o3-deep-research': 0.02, // $0.02 per 1M tokens
    'gpt-image-1': 0.04   // $0.04 per image
  };
  
  calculateOperationCost(operation: AIOperation): CostBreakdown {
    const estimates = {
      'quest_generation': {
        tokens: 1500,
        recommendedModel: 'grok-4',
        costPerOperation: 0.003,
        alternativeCosts: {
          'gpt-5': 0.0045,
          'gpt-5-mini': 0.0003
        }
      },
      
      'code_assistance': {
        tokens: 2000,
        recommendedModel: 'gpt-5',
        costPerOperation: 0.006,
        alternativeCosts: {
          'grok-4': 0.004,
          'gpt-5-mini': 0.0004
        }
      },
      
      'quick_interaction': {
        tokens: 200,
        recommendedModel: 'gpt-5-mini',
        costPerOperation: 0.00004,
        alternativeCosts: {
          'gpt-5': 0.0006,
          'grok-4': 0.0004
        }
      },
      
      'deep_analysis': {
        tokens: 5000,
        recommendedModel: 'o3-deep-research',
        costPerOperation: 0.1,
        alternativeCosts: {
          'grok-4': 0.01,
          'gpt-5': 0.015
        }
      }
    };
    
    return estimates[operation.type];
  }
  
  // Monatliche Kostensch√§tzung f√ºr verschiedene Nutzungsszenarien
  estimateMonthlyCosts(userBase: number, usagePattern: UsagePattern): MonthlyCostEstimate {
    const operationsPerUser = {
      casual: { // 10 Quests/Monat pro User
        quest_generation: 10,
        quick_interaction: 50,
        code_assistance: 5,
        deep_analysis: 1
      },
      regular: { // 30 Quests/Monat pro User
        quest_generation: 30,
        quick_interaction: 150,
        code_assistance: 20,
        deep_analysis: 3
      },
      intensive: { // 100 Quests/Monat pro User
        quest_generation: 100,
        quick_interaction: 500,
        code_assistance: 80,
        deep_analysis: 10
      }
    };
    
    const pattern = operationsPerUser[usagePattern];
    const totalCost = userBase * (
      pattern.quest_generation * 0.003 +
      pattern.quick_interaction * 0.00004 +
      pattern.code_assistance * 0.006 +
      pattern.deep_analysis * 0.1
    );
    
    return {
      totalMonthlyCost: totalCost,
      costPerUser: totalCost / userBase,
      breakdown: this.generateCostBreakdown(pattern, userBase)
    };
  }
}
```

### Kostensch√§tzungen f√ºr verschiedene Szenarien

| Szenario | Nutzer | Operationen/User/Monat | Kosten/User/Monat | Gesamt/Monat |
|----------|--------|------------------------|-------------------|--------------|
| **Startup** | 1,000 | 70 Mixed | ‚Ç¨0.08 | ‚Ç¨80 |
| **Wachstum** | 10,000 | 200 Mixed | ‚Ç¨0.15 | ‚Ç¨1,500 |
| **Enterprise** | 100,000 | 500 Mixed | ‚Ç¨0.25 | ‚Ç¨25,000 |

## ‚ö° Performance-Optimierung / Performance Optimization

### 1. Intelligente Modell-Auswahl
```typescript
// lib/ai/smart-model-selector.ts
export class SmartModelSelector {
  selectOptimalModel(request: AIRequest): ModelSelection {
    const factors = {
      complexity: this.assessComplexity(request),
      urgency: this.assessUrgency(request),
      cost_sensitivity: this.getCostSensitivity(request.userId),
      quality_requirements: this.getQualityRequirements(request.feature)
    };
    
    // Entscheidungsbaum f√ºr Modell-Auswahl
    if (factors.urgency === 'high' && factors.complexity === 'low') {
      return { model: 'gpt-5-mini', confidence: 0.95 };
    }
    
    if (factors.complexity === 'high' && factors.quality_requirements === 'premium') {
      return { model: 'o3-deep-research', confidence: 0.88 };
    }
    
    if (request.feature.includes('code')) {
      return { model: 'gpt-5', confidence: 0.92 };
    }
    
    // Standard-Wahl f√ºr ausgewogene Anforderungen
    return { model: 'grok-4', confidence: 0.85 };
  }
  
  async optimizeTokenUsage(request: AIRequest): Promise<OptimizedRequest> {
    // Prompt-Optimierung basierend auf Modell
    const optimizedPrompt = await this.optimizePromptForModel(
      request.prompt, 
      request.targetModel
    );
    
    // Token-Sch√§tzung
    const estimatedTokens = this.estimateTokenCount(optimizedPrompt);
    
    // Empfehlung f√ºr Kontext-K√ºrzung wenn n√∂tig
    if (estimatedTokens > this.getModelContextLimit(request.targetModel) * 0.8) {
      optimizedPrompt = await this.compressContext(optimizedPrompt);
    }
    
    return {
      ...request,
      prompt: optimizedPrompt,
      estimatedTokens,
      estimatedCost: this.calculateCost(estimatedTokens, request.targetModel)
    };
  }
}
```

### 2. Caching-Strategien
```typescript
// lib/ai/intelligent-cache.ts
export class IntelligentAICache {
  async getCachedResponse(request: AIRequest): Promise<CachedResponse | null> {
    // Semantic Similarity Check f√ºr √§hnliche Anfragen
    const semanticKey = await this.generateSemanticKey(request);
    const cachedResponses = await this.findSimilarCachedResponses(semanticKey);
    
    for (const cached of cachedResponses) {
      const similarity = await this.calculateSimilarity(request, cached.original);
      
      if (similarity > 0.85) { // 85% √Ñhnlichkeit
        // Anpassung der gecachten Antwort an neue Anfrage
        const adaptedResponse = await this.adaptCachedResponse(
          cached.response, 
          request,
          similarity
        );
        
        return {
          response: adaptedResponse,
          cacheHit: true,
          originalCost: cached.originalCost,
          savedCost: this.calculateCost(request),
          similarity
        };
      }
    }
    
    return null;
  }
  
  async cacheResponse(request: AIRequest, response: AIResponse): Promise<void> {
    const cacheEntry = {
      semanticKey: await this.generateSemanticKey(request),
      originalRequest: request,
      response,
      timestamp: new Date(),
      accessCount: 0,
      totalSavedCost: 0,
      ttl: this.calculateTTL(request, response)
    };
    
    await this.storeInCache(cacheEntry);
  }
  
  private calculateTTL(request: AIRequest, response: AIResponse): number {
    // Dynamische TTL basierend auf Content-Typ
    const baseTTL = {
      'quest_generation': 3600 * 24 * 7, // 1 Woche
      'quick_interaction': 3600 * 24,     // 1 Tag  
      'code_assistance': 3600 * 24 * 30,  // 1 Monat
      'deep_analysis': 3600 * 24 * 90     // 3 Monate
    };
    
    return baseTTL[request.type] || 3600 * 24; // Default: 1 Tag
  }
}
```

## üéØ Spezifische Anwendungsf√§lle / Specific Use Cases

### 1. Onboarding und Nutzer-Analyse
```typescript
// Empfehlung: Grok 4 + O3 Deep Research
const onboardingAI = {
  personalityAssessment: 'grok-4',      // Complex reasoning f√ºr Pers√∂nlichkeitsanalyse
  skillGapAnalysis: 'o3-deep-research', // Tiefgehende Analyse
  questRecommendation: 'grok-4'         // Personalisierte Empfehlungen
};

// Kosteneffiziente Alternative f√ºr kleine Teams
const budgetOnboarding = {
  personalityAssessment: 'gpt-5',       // Gute Balance
  skillGapAnalysis: 'grok-4',          // Reduzierte aber ausreichende Tiefe
  questRecommendation: 'gpt-5-mini'     // Schnelle Empfehlungen
};
```

### 2. Echtzeit-Unterst√ºtzung w√§hrend Quests
```typescript
// Empfehlung: GPT-5 Mini f√ºr Geschwindigkeit
const realtimeSupport = {
  hintGeneration: 'gpt-5-mini',         // Schnelle Hilfestellungen
  progressTracking: 'gpt-5-mini',       // Einfache Status-Updates  
  errorAnalysis: 'gpt-5',              // Detailliertere Code-Analyse
  adaptiveFeedback: 'grok-4'           // Personalisiertes Feedback
};
```

### 3. Community und Kollaboration
```typescript
// Mixed Model Approach
const communityFeatures = {
  teamFormation: 'grok-4',             // Complex matching algorithms
  conflictResolution: 'gpt-5',          // Diplomatic communication
  knowledgeSharing: 'gpt-5-mini',      // Quick Q&A responses
  trendAnalysis: 'o3-deep-research'     // Community behavior insights
};
```

### 4. Content-Generierung
```typescript
// Spezial-Modelle je nach Content-Typ
const contentGeneration = {
  questTitles: 'gpt-5-mini',           // Schnelle, kreative Titel
  questDescriptions: 'grok-4',          // Detaillierte, personalisierte Beschreibungen
  codeExamples: 'gpt-5',               // Hochqualitative Code-Beispiele
  visualContent: 'gpt-image-1',         // Bilder und Grafiken
  documentation: 'gpt-5'                // Strukturierte Dokumentation
};
```

## üîÑ Migration und A/B Testing

### 1. Graduelle Modell-Migration
```typescript
// lib/ai/model-migration.ts
export class ModelMigrationManager {
  async migrateToNewModel(
    feature: string,
    currentModel: string,
    targetModel: string,
    rolloutPercentage: number
  ): Promise<MigrationResult> {
    
    // Parallel Testing Setup
    const testUsers = await this.selectTestUsers(rolloutPercentage);
    
    const results = await Promise.all([
      this.runFeatureWithModel(feature, currentModel, this.getControlGroup()),
      this.runFeatureWithModel(feature, targetModel, testUsers)
    ]);
    
    const comparison = await this.compareResults(results[0], results[1]);
    
    return {
      performanceDelta: comparison.performanceDelta,
      costDelta: comparison.costDelta,
      qualityDelta: comparison.qualityDelta,
      userSatisfactionDelta: comparison.userSatisfactionDelta,
      recommendation: this.generateMigrationRecommendation(comparison)
    };
  }
  
  async abTestModels(
    feature: string,
    modelVariants: string[],
    testDuration: number
  ): Promise<ABTestResult> {
    const trafficSplit = 100 / modelVariants.length;
    
    const testResults = await Promise.all(
      modelVariants.map(async (model, index) => {
        const testGroup = await this.createTestGroup(trafficSplit, index);
        return await this.runModelTest(feature, model, testGroup, testDuration);
      })
    );
    
    return this.analyzeABTestResults(testResults);
  }
}
```

### 2. Performance Monitoring
```typescript
// lib/ai/model-monitor.ts
export class ModelPerformanceMonitor {
  async trackModelPerformance(
    modelId: string,
    feature: string,
    metrics: PerformanceMetrics
  ): Promise<void> {
    const performanceData = {
      modelId,
      feature,
      latency: metrics.responseTime,
      cost: metrics.tokenCost,
      qualityScore: await this.calculateQualityScore(metrics.response),
      userSatisfaction: metrics.userRating,
      errorRate: metrics.errorCount / metrics.totalRequests,
      timestamp: new Date()
    };
    
    await this.storePerformanceData(performanceData);
    await this.updateDashboard(performanceData);
    
    // Automatische Alerts bei Performance-Problemen
    if (performanceData.errorRate > 0.05 || performanceData.latency > 10000) {
      await this.triggerAlert(modelId, performanceData);
    }
  }
  
  async generateModelRecommendations(): Promise<ModelRecommendation[]> {
    const recentData = await this.getRecentPerformanceData('7d');
    const analysis = await this.analyzeModelPerformance(recentData);
    
    return analysis.recommendations.map(rec => ({
      feature: rec.feature,
      currentModel: rec.currentModel,
      recommendedModel: rec.suggestedModel,
      expectedImprovement: rec.improvement,
      migrationComplexity: rec.complexity,
      costImpact: rec.costDelta
    }));
  }
}
```

## üìà ROI-Kalkulation / ROI Calculation

### KI-Investment ROI-Rechner
```typescript
// lib/ai/roi-calculator.ts
export class AIROICalculator {
  calculateFeatureROI(
    feature: string,
    modelChoice: string,
    userBase: number,
    timeframe: number // months
  ): ROIAnalysis {
    
    const costs = this.calculateTotalCosts(modelChoice, userBase, timeframe);
    const benefits = this.calculateBenefits(feature, userBase, timeframe);
    
    return {
      totalCosts: costs.total,
      directBenefits: benefits.direct,
      indirectBenefits: benefits.indirect,
      roi: (benefits.total - costs.total) / costs.total,
      paybackPeriod: costs.total / (benefits.total / timeframe),
      breakdown: {
        costs: costs.breakdown,
        benefits: benefits.breakdown
      },
      recommendations: this.generateROIRecommendations(costs, benefits)
    };
  }
  
  private calculateBenefits(feature: string, users: number, months: number): BenefitCalculation {
    const benefitModels = {
      'personalized_quests': {
        userEngagement: users * 0.15 * 5,    // 15% mehr Engagement, ‚Ç¨5 Wert
        retention: users * 0.10 * 20,        // 10% bessere Retention, ‚Ç¨20 Wert
        satisfaction: users * 0.20 * 2       // 20% h√∂here Zufriedenheit, ‚Ç¨2 Wert
      },
      'ai_code_assistance': {
        learningSpeed: users * 0.25 * 15,    // 25% schnelleres Lernen, ‚Ç¨15 Wert
        codeQuality: users * 0.30 * 10,      // 30% bessere Code-Qualit√§t, ‚Ç¨10 Wert
        timeToCompletion: users * 0.20 * 8   // 20% schnellere Quest-Completion, ‚Ç¨8 Wert
      },
      'intelligent_recommendations': {
        discoveryRate: users * 0.40 * 3,     // 40% mehr Content-Discovery, ‚Ç¨3 Wert  
        questCompletion: users * 0.18 * 12,  // 18% h√∂here Completion-Rate, ‚Ç¨12 Wert
        crossSelling: users * 0.08 * 25      // 8% mehr Premium-Features, ‚Ç¨25 Wert
      }
    };
    
    const model = benefitModels[feature];
    const total = Object.values(model).reduce((sum, value) => sum + value, 0) * months;
    
    return {
      direct: total * 0.7,  // 70% direkt messbar
      indirect: total * 0.3, // 30% indirekte Vorteile
      total,
      breakdown: model
    };
  }
}
```

## üõ°Ô∏è Sicherheit und Compliance

### Modell-spezifische Sicherheits√ºberlegungen
```typescript
// lib/ai/security-guidelines.ts
export const MODEL_SECURITY_PROFILES = {
  'grok-4': {
    dataRetention: 'zero', // Keine Speicherung von Trainingsdaten
    privacy: 'high',
    compliance: ['GDPR', 'CCPA'],
    recommendedFor: ['user_data', 'personal_content'],
    restrictions: ['no_pii_logging']
  },
  
  'gpt-5': {
    dataRetention: 'minimal', // 30 Tage API-Logs
    privacy: 'medium',
    compliance: ['GDPR', 'CCPA', 'SOC2'],
    recommendedFor: ['code_generation', 'general_content'],
    restrictions: ['content_filtering_required']
  },
  
  'o3-deep-research': {
    dataRetention: 'extended', // F√ºr Verbesserung der Analyse
    privacy: 'medium',
    compliance: ['GDPR', 'enterprise_standards'],
    recommendedFor: ['analytics', 'research'],
    restrictions: ['no_sensitive_data', 'anonymization_required']
  }
};
```

## üìã Entscheidungs-Checkliste / Decision Checklist

### Bevor Sie ein Modell ausw√§hlen:

#### ‚úÖ Anforderungs-Analyse
- [ ] **Anwendungsfall klar definiert?**
- [ ] **Qualit√§ts-Anforderungen spezifiziert?**
- [ ] **Latenz-Anforderungen dokumentiert?**
- [ ] **Budget-Constraints ber√ºcksichtigt?**
- [ ] **Skalierungsanforderungen geplant?**

#### ‚úÖ Technische √úberlegungen
- [ ] **Token-Limits ausreichend?**
- [ ] **Integration-Komplexit√§t bewertet?**
- [ ] **Fallback-Strategien definiert?**
- [ ] **Caching-M√∂glichkeiten gepr√ºft?**
- [ ] **Monitoring eingerichtet?**

#### ‚úÖ Business-Faktoren
- [ ] **ROI-Kalkulation erstellt?**
- [ ] **Konkurrenzvergleich durchgef√ºhrt?**
- [ ] **Nutzer-Impact bewertet?**
- [ ] **Langzeit-Strategie entwickelt?**
- [ ] **Team-Capabilities gepr√ºft?**

#### ‚úÖ Compliance und Sicherheit
- [ ] **Datenschutz-Anforderungen erf√ºllt?**
- [ ] **Sicherheits-Audit durchgef√ºhrt?**
- [ ] **Compliance-Standards eingehalten?**
- [ ] **Risiko-Assessment abgeschlossen?**

## üéØ Quick-Referenz / Quick Reference

### Sofortige Modell-Empfehlungen:

| Wenn du brauchst... | Verwende... | Warum |
|-------------------|------------|-------|
| **Schnelle Antworten** | GPT-5 Mini | Geschwindigkeit + Kosten |
| **Code-Hilfe** | GPT-5 | Beste Code-Performance |
| **Personalisierung** | Grok 4 | Superior Reasoning |
| **Tiefe Analyse** | O3 Deep Research | Unmatched Depth |
| **Bilder** | GPT Image 1 | Best Visual Quality |
| **Allround-L√∂sung** | Grok 4 | Gute Balance |
| **Budget-Option** | GPT-5 Mini | Kosteneffizient |
| **Premium-Experience** | O3 Deep Research | H√∂chste Qualit√§t |

---

*Dieser Leitfaden wird regelm√§√üig aktualisiert, wenn neue Modelle verf√ºgbar werden oder sich Performance-Charakteristika √§ndern.*